---
title: "Report: BIP project"
author: "Alberto Parravicini, Simone Ripamonti, Luca Stornaiuolo"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# DATA PREPROCESSING
* INITIAL ATTRIBUTES
+ "Zona": [STRING];
+ "Area": [STRING];
+ "Sottoarea": [STRING];
+ "Categoria_prodotto": [STRING];
+ "Data": [STRING];
+ "Vendite": [NUMBER];
+ "LATITUDINE": [NUMBER];
+ "LONGITUDINE": [NUMBER];
* FINAL ATTRIBUTES
+ Attributes extracted from "Categoria_prodotto"
- "prod": [NUMBER] {string manipulation; cast to integer};
+ Attributes extracted from "Zona", "Area" and "Sottoarea":
- "zona": [NUMBER] {string manipulation; cast to integer};
- "area": [NUMBER] {string manipulation; cast to integer};
- "sottoarea": [NUMBER] {string manipulation; cast to integer};
- "key": [STRING] {string manipulation};
+ Attributes extracted from "Data"
- "data": [STRING];
- "giorno_mese": [NUMBER] {cast to date; date manipulation};
- "giorno_settimana": [NUMBER] {cast to date; date manipulation};
- "giorno_anno": [NUMBER] {cast to date; date manipulation};
- "mese": [NUMBER] {cast to date; date manipulation};
- "settimana_anno": [NUMBER] {cast to date; date manipulation};
- "anno": [NUMBER] {cast to date; date manipulation};
- "weekend": [NUMBER (BOOLEAN)] {cast to date; date manipulation};
- "stagione": [STRING] {cast to date; date manipulation};
- "primo_del_mese": [NUMBER (BOOLEAN)] {cast to date; date manipulation};
+ Attributes extracted from "Data" and GPS information
- "vacanza": [NUMBER (BOOLEAN)] {cast to date; date manipulation};
+ Attributes extracted from "Vendite"
- "vendite": [NUMBER] {attribute renaming};
- "sp_anno": [NUMBER] {number manipulation};
- "sp_mese": [NUMBER] {number manipulation};
- "sp_settimana": [NUMBER] {number manipulation};
- "vendite_giorn_tot": [NUMBER] {number manipulation};
- "vendite_missing": [NUMBER (BOOLEAN)] {number manipulation};
- "vendite_giorn_prod": [NUMBER] {number manipulation; PREDICTION PROCESS};
+ Attributes extracted from GPS information
- "latitudine": [NUMBER] {attribute renaming};
- "longitudine": [NUMBER] {attribute renaming};
- "cluster3": [NUMBER] (GPS data manipulation; CLUSTERING PROCESS);
- "cluster6": [NUMBER] (GPS data manipulation; CLUSTERING PROCESS);
- "cluster20": [NUMBER] (GPS data manipulation; CLUSTERING PROCESS);
# CLUSTERING PROCESS
* HIERARCHICAL CLUSTERING (GPS information)
+ Elbow Method Analysis: number of cluster = 6;
* KMEANS CLUSTERING (GPS information)
+ "cluster6": from Elbow Method Analysis;
+ "cluster3": NORD, CENTRO, SUD Analysis;
+ "cluster20": REGIONI Analysis;
# PREDICTION PROCESS
* RANDOM FOREST
+ Single model for all sottoarea;
+ Ranger random forest model builder;
+ Ranger random forest model builder;
* SARIMA PREDICTION
+ Time Series Casting;
+ Correlation Analysis;
+ Regressors (External Input);
* XGBOOST PREDICTION
+ Single XGBoost;
+ Multiple XGBoost;
# MODELS EVALUATION
* SSE;
* MAPE;
knitr::opts_chunk$set(echo = TRUE)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
gps <- read.csv("C:/Users/Simone/Desktop/DM-Project/gps.csv", stringsAsFactors=FALSE)
View(gps)
library(rworldmap)
newmap3 <- getMap(resolution = "low")
plot(newmap3, xlim = c(-10, 30), ylim = c(40, 50), asp = 1)
points(gps[20,]$LONGITUDINE, gps[20,]$LATITUDINE, col = "red", cex = .2)
newmap3 <- getMap(resolution = "low")
plot(newmap3, xlim = c(-10, 30), ylim = c(40, 50), asp = 1)
# points(gps$LONGITUDINE, gps$LATITUDINE, col = "red", cex = .2)
points(gps[20,]$LONGITUDINE, gps[20,]$LATITUDINE, col = "red", cex = .2)
points(gps[32,]$LONGITUDINE, gps[32,]$LATITUDINE, col = "red", cex = .2)
points(gps[77,]$LONGITUDINE, gps[77,]$LATITUDINE, col = "red", cex = .2)
library(rworldmap)
newmap3 <- getMap(resolution = "low")
plot(newmap3, xlim = c(-10, 30), ylim = c(40, 50), asp = 1)
# points(gps$LONGITUDINE, gps$LATITUDINE, col = "red", cex = .2)
points(gps[20,]$LONGITUDINE, gps[20,]$LATITUDINE, col = 1,asp=1)
points(gps[32,]$LONGITUDINE, gps[32,]$LATITUDINE, col = 2, asp=1)
points(gps[77,]$LONGITUDINE, gps[77,]$LATITUDINE, col = 3, asp=1)
res_test_train_600 <- read.csv("C:/Users/Simone/Desktop/DM-Project/forests temp data/res_test_train_600.csv", stringsAsFactors=FALSE)
View(res_test_train_600)
res_test_train_1200 <- read.csv("C:/Users/Simone/Desktop/DM-Project/forests temp data/res_test_train_1200.csv", stringsAsFactors=FALSE)
View(res_test_train_1200)
library(xts)
library(ggplot2)
library(dplyr)
library(tseries)
library(PerformanceAnalytics)
library(forecast)
library(astsa)
library(Metrics)
library(xgboost)
library(ranger)
library(ggthemes) # visualization
source("src/scoring functions.R")
library(stringr)
setClass(Class = "forest_pred", representation(predictions = "numeric", prediction_table = "data.frame", sse = "numeric"))
setClass(Class = "full_forest_pred", representation(predictions = "data.frame", sse_list = "numeric"))
compute_errors <- function(prediction, test, write = F) {
results <- data.frame(matrix(NA, ncol=6, nrow=0))
for (s in unique(prediction$sottoarea)){
local_test <- filter(test, sottoarea==s)
local_pred <- filter(prediction, sottoarea==s)
for (p in unique(local_test$prod)){
sse <- (1/nrow(filter(local_test, prod==p))*sum((filter(local_pred, prod==p)$vendite - filter(local_test, prod==p)$vendite)^2))
mape <- mean(abs(filter(local_pred, prod==p)$vendite - filter(local_test, prod==p)$vendite)/mean(filter(local_test, prod==p)$vendite))
maxape <- max(abs(filter(local_pred, prod==p)$vendite - filter(local_test, prod==p)$vendite)/mean(filter(local_test, prod==p)$vendite))
temp_row <- data.frame(sottoarea=s, prod=p, sse=sse, mape=mape, maxape=maxape)
results <- rbind(results, temp_row)
}
}
if (write) {
write.csv(results, file="Results/risultati_forest_no[20(1-2),78(2),32(2)]_200_trees.csv", row.names=FALSE)
}
return(results)
}
View(res_test_train_1200)
dataset_polimi_final_with_holidays_v2 <- read.csv("C:/Users/Simone/Desktop/DM-Project/Modified data/dataset_polimi_final_with_holidays_v2.csv", stringsAsFactors=FALSE)
View(dataset_polimi_final_with_holidays_v2)
setwd("C:/Users/Simone/Desktop/DM-Project")
sink("C:/Users/Simone/Desktop/DM-Project/forests temp data/scoring")
dataset <- dataset_polimi_final_with_holidays_v2
library(xts)
library(ggplot2)
library(dplyr)
library(tseries)
library(PerformanceAnalytics)
library(forecast)
library(astsa)
library(Metrics)
library(xgboost)
library(ranger)
library(ggthemes) # visualization
library(normwhn.test)
library(nortest)
library(nortestARMA)
prediction_length = 10
# Remove the x column, if present
dataset <- dataset[ , !(names(dataset) %in% c("X"))]
# Build a smaller datasetset, for testing
# dataset <- dataset[sample(1:nrow(dataset), 1000), ]
# Convert dates to class "Data"
dataset$data <- as.Date(dataset$data)
# Convert "vendite" to numeric values if needed
if (class(dataset$vendite) == "factor") {
dataset$vendite <- as.numeric(levels(dataset$vendite))[dataset$vendite]
}
# Turn some features to factors
factorVars <- c('zona','area', "sottoarea",
'prod','giorno_mese', "giorno_settimana", "giorno_anno", "vendite_missing", "mese", "settimana_anno", "anno", "weekend","stagione", "key", "primo_del_mese", "cluster3", "cluster6", "cluster20", "vacanza")
dataset[factorVars] <- lapply(dataset[factorVars], function(x) as.factor(x))
dataset <- dataset[order(dataset$prod, dataset$zona, dataset$area, dataset$sottoarea), ]
# remove sottoarea 20
dataset <- filter(dataset, sottoarea!=20)
# remove sottoarea 78 prodotto 2
temp <- filter(dataset, sottoarea==78, prod==1)
dataset <- filter(dataset, sottoarea!=78)
dataset <- rbind(dataset, temp)
# remove sottoarea 30 prodotto 2
temp <- filter(dataset, sottoarea==32, prod==1)
dataset <- filter(dataset, sottoarea!=32)
dataset <- rbind(dataset, temp)
train <- filter(dataset, data <= max(data) - prediction_length)
test <- filter(dataset, data > max(data) - prediction_length)
predset <- read.csv("Modified data/predset_complete_with_clusters.csv", stringsAsFactors = F)
predset$vendite <- 0
compute_errors <- function(prediction, test, write = F) {
results <- data.frame(matrix(NA, ncol=6, nrow=0))
for (s in unique(prediction$sottoarea)){
local_test <- filter(test, sottoarea==s)
local_pred <- filter(prediction, sottoarea==s)
for (p in unique(local_test$prod)){
sse <- (1/nrow(filter(local_test, prod==p))*sum((filter(local_pred, prod==p)$vendite - filter(local_test, prod==p)$vendite)^2))
mape <- mean(abs(filter(local_pred, prod==p)$vendite - filter(local_test, prod==p)$vendite)/mean(filter(local_test, prod==p)$vendite))
maxape <- max(abs(filter(local_pred, prod==p)$vendite - filter(local_test, prod==p)$vendite)/mean(filter(local_test, prod==p)$vendite))
temp_row <- data.frame(sottoarea=s, prod=p, sse=sse, mape=mape, maxape=maxape)
results <- rbind(results, temp_row)
}
}
if (write) {
write.csv(results, file="Results/risultati_forest_no[20(1-2),78(2),32(2)]_200_trees.csv", row.names=FALSE)
}
return(results)
}
results600 <- compute_errors(res_test_train_600, test)
results1200 <- computer_errors(res_test_train_1200, test)
results1200 <- compute_errors(res_test_train_1200, test)
write.csv(results600, file="forests temp data/compute_errors_600.csv", row.names=FALSE)
write.csv(results1200, file="forests temp data/compute_errors_1200.csv", row.names=FALSE)
sink()
